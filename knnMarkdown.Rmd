---
title: "K-Nearest Neighbors"
author: "Diego Candela Salomón"
date: "14/9/2020"
output:
  pdf_document: default
  html_document: default
---


##K-nearest Neighbors

Knn es uno de los algoritmos más empleados en problemas de clasificación. Se puede utilizar caret para entrenar modelos de clasificación en knn. 


###Funciones

Dado que las predicciones de un modelo knn se devuelven como dos columnas con la probabilidad calculadada de pertenecer a cada categoría, se escribe una función para igualar el formato de las predicciones con el de las etiquetas del data_test.

La función aciertos_a_confusión tiene un argumento:

* df: el dataframe de predicciones.

El ouput de la función es el mismo dataframe con una columna con las predicciones del modelo igualadas al formato de las etiquetas. 

```
aciertos_a_confusion <- function(df){
  df <- as.data.frame(df)
  df$aciertos <- 0
  for (i in 1:length(df$aciertos)){
    if ((df[i,3] > df[i,2])){
      df[i,4] <- 1
    }
  }
  return(df)
}
```

###Importar datos

Dado que el formato de los datos se mantiene para el resto de algoritmos de ahora en adelante, el proceso de importación es el mismo que hemos visto hasta ahora. Generaremos dos modelos a partir de sus correspondientes conjuntos de datos. Tras importar el conjunto de datos recogidos antes del comienzo de la partida, realizamos un cbind de las etiquetas de data_train con data_train

```
data_train         <- readRDS("./datosPreGame/data_train")
data_test          <- readRDS("./datosPreGame/data_test")
labels_data_train  <- readRDS("./datosPreGame/labels_train")
labels_data_test   <- readRDS("./datosPreGame/labels_test")

data_train <- cbind(labels_data_train, data_train)
```

Dada la cantidad de predictores que tiene el dataset y teniendo en cuenta que se encuentran en formato dummy, knn tiene problemas para generar un modelo cuando las variables tienen varianza próxima a cero. Para esto caret dispone de la función "nearZeroVar" que genera un índice de variables que cumplen estas característas para poder eliminarlas del dataset

```
indiceCerosTrain <- nearZeroVar(data_train)

data_train       <- data_train[,-indiceCerosTrain]
```
###Preparando caret

Una vez los datos están preparados para entrenar el modelo, preparamos los parámetros de caret para knn

```
control <- trainControl(method = "repeatedcv",
                        repeats = 3,
                        verboseIter = T)

knn_1 <- train(labels_data_train~.,
               data_train,
               'knn',
               trControl = control,
               tuneLength = 20
)
```
Una vez se ha entrenado el modelo se ha de poner a prueba frente al data_test. Los resultados están expuestos en el documento principal de este proyecto.

Primero aplicamos el mismo índice de la función "nearZeroVar" al set de testeo y luego utilizamos la función del paquete base de R "predict". La función ha de ser ajustada para el parámetro k óptimo obtenido en el modelo

Guardamos esas predicciones en un dataframe para generar la matriz de confusión con la función proporcionada por el paquete caret una vez pasamos esas predicciones por la función aciertos_a_confusion.

Con el fin de asegurar que no ha habido ningún cambio de formato y que el vector predictions tiene los mismos niveles que las etiquetas del data_test añadimos la linea 110 y generamos la matriz de confusión.

```
data_test <- cbind(labels_data_test, data_test)
data_test <- data_test[,-indiceCerosTrain]
data_test <- data_test[,-1]

levels(labels_data_test) <- <- c("0","1")

predictions  <- predict(knn_1, 
                        newdata = data_test,
                        k = 9,
                        type = "prob", 
                        prob=T)
                        
predicciones <- as.data.frame(cbind(labels_data_test, predictions))

probs1 <- aciertos_a_confusion(predicciones)

matriz_confusion <- confusionMatrix(data      = as.factor(probs1[,4]),
                                    reference = as.factor(probs1[,1]))

```
Una vez hemos generado la matriz de confusión podemo proceder a realizar el cálculo del RMSE para la comparación de los modelos.

```
residuals_preGame <- as.numeric(labels_data_test) - as.numeric(probs1[,4])
RMSE_preGame      <- sqrt(mean(residuals_preGame^2))

```
Una vez tenemos el primer modelo, podemos proceder a eliminar los datasets del entorno de trabajo para importar los datasets completos y entrenar el segundo modelo

```
rm(data_train,data_test)

data_train         <- readRDS("./datosCompleto/data_train")
data_test          <- readRDS("./datosCompleto/data_test")

data_train <- cbind(labels_data_train, data_train)

```
Repetimos el mismo proceso para generar el índice de variables con varianza cercanas a 0

```
indiceCerosTrain <- nearZeroVar(data_train)

data_train       <- data_train[,-indiceCerosTrain]

```
Y podemos proceder a generar el segundo modelo con los mismos parámetros

```
control <- trainControl(method = "repeatedcv",
                        repeats = 3,
                        verboseIter = T)

knn_2 <- train(labels_data_train~.,
               data_train,
               'knn',
               trControl = control,
               tuneLength = 20
)
```
Realizamos el mismo proceso para las predicciones, matriz de confusión y cálculo del RMSE

```
predictions  <- predict(knn_2, 
                        newdata = data_test,
                        k = 9,
                        type = "prob", 
                        prob=T)

predicciones <- cbind(labels_data_test, predictions)

predicciones <- as.data.frame(cbind(labels_data_test, predictions))

probs1 <- aciertos_a_confusion(predicciones)

matriz_confusion <- confusionMatrix(data      = as.factor(probs1[,4]),
                                    reference = as.factor(probs1[,1]))

residuals_completo <- as.numeric(labels_data_test) - as.numeric(probs1[,4])
RMSE_completo      <- sqrt(mean(residuals_completo^2))

```


